{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alessandra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alessandra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext as sc\n",
    "import pyspark as sp\n",
    "\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "import heapq\n",
    "from heapq import heappush, heappop\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "texas1 = pd.read_csv(\"data/Airbnb_Texas_Rentals.csv\")\n",
    "texas1 = texas1.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rate_per_night</th>\n",
       "      <th>bedrooms_count</th>\n",
       "      <th>city</th>\n",
       "      <th>date_of_listing</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$27</td>\n",
       "      <td>2</td>\n",
       "      <td>Humble</td>\n",
       "      <td>May 2016</td>\n",
       "      <td>Welcome to stay in private room with queen bed...</td>\n",
       "      <td>30.020138</td>\n",
       "      <td>-95.293996</td>\n",
       "      <td>2 Private rooms/bathroom 10min from IAH airport</td>\n",
       "      <td>https://www.airbnb.com/rooms/18520444?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$149</td>\n",
       "      <td>4</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>November 2010</td>\n",
       "      <td>Stylish, fully remodeled home in upscale NW – ...</td>\n",
       "      <td>29.503068</td>\n",
       "      <td>-98.447688</td>\n",
       "      <td>Unique Location! Alamo Heights - Designer Insp...</td>\n",
       "      <td>https://www.airbnb.com/rooms/17481455?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$59</td>\n",
       "      <td>1</td>\n",
       "      <td>Houston</td>\n",
       "      <td>January 2017</td>\n",
       "      <td>'River house on island close to the city' \\nA ...</td>\n",
       "      <td>29.829352</td>\n",
       "      <td>-95.081549</td>\n",
       "      <td>River house near the city</td>\n",
       "      <td>https://www.airbnb.com/rooms/16926307?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$60</td>\n",
       "      <td>1</td>\n",
       "      <td>Bryan</td>\n",
       "      <td>February 2016</td>\n",
       "      <td>Private bedroom in a cute little home situated...</td>\n",
       "      <td>30.637304</td>\n",
       "      <td>-96.337846</td>\n",
       "      <td>Private Room Close to Campus</td>\n",
       "      <td>https://www.airbnb.com/rooms/11839729?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$75</td>\n",
       "      <td>2</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>February 2017</td>\n",
       "      <td>Welcome to our original 1920's home. We recent...</td>\n",
       "      <td>32.747097</td>\n",
       "      <td>-97.286434</td>\n",
       "      <td>The Porch</td>\n",
       "      <td>https://www.airbnb.com/rooms/17325114?location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  average_rate_per_night bedrooms_count         city date_of_listing  \\\n",
       "0                    $27              2       Humble        May 2016   \n",
       "1                   $149              4  San Antonio   November 2010   \n",
       "2                    $59              1      Houston    January 2017   \n",
       "3                    $60              1        Bryan   February 2016   \n",
       "4                    $75              2   Fort Worth   February 2017   \n",
       "\n",
       "                                         description   latitude  longitude  \\\n",
       "0  Welcome to stay in private room with queen bed...  30.020138 -95.293996   \n",
       "1  Stylish, fully remodeled home in upscale NW – ...  29.503068 -98.447688   \n",
       "2  'River house on island close to the city' \\nA ...  29.829352 -95.081549   \n",
       "3  Private bedroom in a cute little home situated...  30.637304 -96.337846   \n",
       "4  Welcome to our original 1920's home. We recent...  32.747097 -97.286434   \n",
       "\n",
       "                                               title  \\\n",
       "0    2 Private rooms/bathroom 10min from IAH airport   \n",
       "1  Unique Location! Alamo Heights - Designer Insp...   \n",
       "2                          River house near the city   \n",
       "3                       Private Room Close to Campus   \n",
       "4                                          The Porch   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.airbnb.com/rooms/18520444?location...  \n",
       "1  https://www.airbnb.com/rooms/17481455?location...  \n",
       "2  https://www.airbnb.com/rooms/16926307?location...  \n",
       "3  https://www.airbnb.com/rooms/11839729?location...  \n",
       "4  https://www.airbnb.com/rooms/17325114?location...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('expand_frame_repr',False)\n",
    "texas1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create docuemnts as tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'data/docs/'\n",
    "path2 = '.tsv'\n",
    "stemmed_path='data/tokenized_docs/'\n",
    "sp = string.punctuation+'“”–’'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_step(doc):\n",
    "    \"\"\"\n",
    "    takes as input the string of the document\n",
    "    removes stopwords, punctuation and makes stemming \n",
    "    \"\"\"\n",
    "    \n",
    "    # check if it's a nan value \n",
    "\n",
    "    if isinstance(doc, float):\n",
    "        return str(doc)\n",
    "    \n",
    "    doc=doc.replace(\"\\\\n\", \" \")\n",
    "    # punctuations\n",
    "    doc = [ c if c not in sp else \" \" for c in doc ]\n",
    "    doc = ''.join(doc)\n",
    "    # stopwords\n",
    "    doc = [ word for word in doc.split() if word.lower() not in stopwords.words('english') ]\n",
    "    doc = ' '.join(doc)\n",
    "    \n",
    "    # stemming\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(doc)\n",
    "    \n",
    "    w_lst = []\n",
    "    for w in words:\n",
    "        w_lst.append(ps.stem(w))\n",
    "    \n",
    "    # something else\n",
    "    \n",
    "    return ' '.join(w_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing create the tsv files.\n",
    "We created vocabulary parsing every document and updating it when the algorithm finds a new word. \n",
    "Format of vocabulary => 'string':integer.\n",
    "Creation of ii1:\n",
    "The first inverted index is built, updating it every time a word is find in a document.\n",
    "At the end we stored vocabulary and the inverted index using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    n=len(data)\n",
    "\n",
    "    for i in range(n):\n",
    "        with open(path1 + 'doc_'+ str(i) + '.tsv', 'w', encoding = \"utf-8\") as doc:\n",
    "            a = csv.writer(doc, delimiter='\\t')\n",
    "            a.writerow([data.iloc[i]['average_rate_per_night'],data.iloc[i]['bedrooms_count'], data.iloc[i]['city'],\n",
    "                        data.iloc[i]['date_of_listing'], data.iloc[i]['description'],\n",
    "                        data.iloc[i]['latitude'],\n",
    "                        data.iloc[i]['longitude'],\n",
    "                        data.iloc[i]['title'],\n",
    "                        data.iloc[i]['url']])\n",
    "\n",
    "    return\n",
    "\n",
    "def create_vocabulary_and_ii1 (data):\n",
    "    n = len(data)\n",
    "    vocabulary = {}\n",
    "    ii1 = {}    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        # creating a tokenized string with title and description\n",
    "        tokenized_str = (remove_step(data.iloc[i]['title']) + ' ' \n",
    "                                     + remove_step(data.iloc[i]['description']))\n",
    "\n",
    "        # creating the dictionary\n",
    "        for term in tokenized_str.split(' '):\n",
    "            if term in vocabulary.keys():\n",
    "                term_id = vocabulary[term]\n",
    "            else:\n",
    "                vocabulary[term] = cnt\n",
    "                term_id = cnt\n",
    "                cnt+=1\n",
    "\n",
    "            if term_id not in ii1.keys():\n",
    "                ii1[term_id] = ['doc_'+str(i)]\n",
    "            else:\n",
    "                lista = ii1[term_id]\n",
    "                document = 'doc_'+str(i)\n",
    "                if document in lista:\n",
    "                    continue\n",
    "                else:        \n",
    "                    ii1[term_id].append('doc_'+str(i))\n",
    "\n",
    "    # store vocabulary in pickle format\n",
    "    save_obj(vocabulary, 'vocabulary')\n",
    "    save_obj(ii1, 'inverted_index_1')\n",
    "    return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_vocabulary and inverted index 1 (for the first search engine)\n",
    "create_vocabulary_and_ii1(texas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run if you don't want to waste time :-D \n",
    "preprocessing(texas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_engine_1(query): \n",
    "    \n",
    "    query = remove_step(query)\n",
    "    query = list(set(query.split(' ')))\n",
    "    \n",
    "    lst_of_lst=[]\n",
    "    \n",
    "    vocabulary = load_obj('vocabulary')\n",
    "    ii1 = load_obj('inverted_index_1')\n",
    "    \n",
    "    for w in query:\n",
    "        if w not in vocabulary:\n",
    "            print('No results')\n",
    "            return\n",
    "        i = vocabulary[w]\n",
    "        lst_of_lst.append(ii1[i])\n",
    "\n",
    "\n",
    "    doc_list = set.intersection(*[set(sublist) for sublist in lst_of_lst])\n",
    "    doc_list = list(doc_list)\n",
    "    dl = len(doc_list)\n",
    "    \n",
    "    if dl ==0:\n",
    "        print('No results')\n",
    "        return\n",
    "\n",
    "    list_for_df=[]\n",
    "    for i in range(dl):\n",
    "        with open (\"data/docs/\" + doc_list[i] + '.tsv') as doc:\n",
    "            row = doc.read()\n",
    "            lst = row.split('\\t')\n",
    "            lst = [lst[7],lst[4],lst[2],lst[8]]\n",
    "            list_for_df.append(lst)\n",
    "        \n",
    "    df=pd.DataFrame(list_for_df, columns=['Title', 'Description', 'City', 'Url'])\n",
    "    \n",
    "    return df.head(5)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = load_obj('vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>City</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Padre Beach View Home, Walk to Beach</td>\n",
       "      <td>This 4BR, 3BA Padre Beach View Home is just st...</td>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>https://www.airbnb.com/rooms/18451940?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Key Lime Cabin</td>\n",
       "      <td>If you need a relaxing place to stay that is h...</td>\n",
       "      <td>Matagorda</td>\n",
       "      <td>https://www.airbnb.com/rooms/11312175?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Isla Del Sol beachfront condo</td>\n",
       "      <td>Isla Del Sol is a small, quiet beachfront comp...</td>\n",
       "      <td>South Padre Island</td>\n",
       "      <td>https://www.airbnb.com/rooms/12188975?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beach house on private resort</td>\n",
       "      <td>Relaxing, comfortable, and very clean home wit...</td>\n",
       "      <td>Port Isabel</td>\n",
       "      <td>https://www.airbnb.com/rooms/16338158?location...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looks like Coastal Living Magazine</td>\n",
       "      <td>Gorgeous- Old world charm w modern convenience...</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>https://www.airbnb.com/rooms/6119177?location=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title  \\\n",
       "0  Padre Beach View Home, Walk to Beach   \n",
       "1                        Key Lime Cabin   \n",
       "2         Isla Del Sol beachfront condo   \n",
       "3         Beach house on private resort   \n",
       "4    Looks like Coastal Living Magazine   \n",
       "\n",
       "                                         Description                City  \\\n",
       "0  This 4BR, 3BA Padre Beach View Home is just st...      Corpus Christi   \n",
       "1  If you need a relaxing place to stay that is h...           Matagorda   \n",
       "2  Isla Del Sol is a small, quiet beachfront comp...  South Padre Island   \n",
       "3  Relaxing, comfortable, and very clean home wit...         Port Isabel   \n",
       "4  Gorgeous- Old world charm w modern convenience...           Galveston   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.airbnb.com/rooms/18451940?location...  \n",
       "1  https://www.airbnb.com/rooms/11312175?location...  \n",
       "2  https://www.airbnb.com/rooms/12188975?location...  \n",
       "3  https://www.airbnb.com/rooms/16338158?location...  \n",
       "4  https://www.airbnb.com/rooms/6119177?location=...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine_1('beach')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_with_tf(data):\n",
    "    vocabulary = load_obj('vocabulary')\n",
    "    n = len(data)\n",
    "    \n",
    "    ii2 = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        tokenized_str = (remove_step(data.iloc[i]['title']) + ' ' \n",
    "                                     + remove_step(data.iloc[i]['description']))\n",
    "    \n",
    "        for term in tokenized_str.split(' '):\n",
    "            doc_name = 'doc_%s'%i\n",
    "            ii2[term].append((doc_name,1))\n",
    "        \n",
    "    return ii2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii2 = dict_with_tf(texas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ SPARK\n",
    "nSlices = 5\n",
    "for key,values in ii2.items():\n",
    "    \n",
    "    sc = sp.SparkContext(appName = 'parallelization')\n",
    "    \n",
    "    newlst = sc.parallelize(values, nSlices)\n",
    "    \n",
    "    newlst = newlst.reduceByKey(lambda a,b:a+b)\n",
    "    \n",
    "    ii2[key] = newlst.take(len(values))\n",
    "#     need to normalize by the len of the document\n",
    "\n",
    "    sc.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(ii2,'inverted_index_onlyTF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    II with TF:\n",
    "    Taking each list for each term in the inverted index,\n",
    "    we wanted to find the occurrencies for that term in each document.\n",
    "    Thus, we created the inverted index with every document appended inside the value of each \n",
    "    term (the key of the dictionary), \n",
    "    and using in a loop the reduce_doc_list method.\n",
    "    In this method we reduced the repetitions of the same docs in each list, summing them. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_doc_list(doc_list):\n",
    "    \"\"\"\n",
    "    function called by dict_TFIDF\n",
    "    \n",
    "    It reduces the list of documents into a list \n",
    "    of tuple with doc_id and its occurencies\n",
    "    \n",
    "    input:\n",
    "    - list \n",
    "    output:\n",
    "    - list \n",
    "    \"\"\"\n",
    "    tf_term_i = Counter(doc_list)\n",
    "    doc_tf_lst = []\n",
    "    doc_tf_lst = [tuple([key,value]) for key,value in tf_term_i.items()]\n",
    "    return doc_tf_lst\n",
    "\n",
    "def compute_ii2_TFIDF(ii2,n):\n",
    "    \"\"\"\n",
    "    compute the ii2_TFIDF\n",
    "    input:\n",
    "    - inverted index matrix (with TF)\n",
    "    - number of documents\n",
    "    output:\n",
    "    - ii2 \n",
    "    \"\"\"\n",
    "    for key, value in ii2.items():\n",
    "        N = len(value)\n",
    "        new_list = []\n",
    "        for item in value:\n",
    "            new_list.append(tuple([item[0], round(float(item[1])* log(n/N),3)]))\n",
    "            \n",
    "        ii2[key] = new_list\n",
    "    return ii2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_with_TFIDF(data):\n",
    "    \"\"\"\n",
    "    creates the TFIDF inverted index as dict\n",
    "    and store it into a pickle file\n",
    "    input:\n",
    "    - data\n",
    "    \"\"\"\n",
    "    vocabulary = load_obj('vocabulary')\n",
    "    n = len(data)\n",
    "    \n",
    "    ii2 = defaultdict(list)\n",
    "    \n",
    "    for i in range(n):\n",
    "        tokenized_str = (remove_step(data.iloc[i]['title']) + ' ' \n",
    "                                     + remove_step(data.iloc[i]['description']))\n",
    "    \n",
    "        for term in tokenized_str.split(' '):\n",
    "            doc_name = 'doc_%s'%i\n",
    "            ii2[vocabulary[term]].append(doc_name)\n",
    "            \n",
    "    \n",
    "    for key,value in ii2.items():\n",
    "        ii2[key] = reduce_doc_list(value)\n",
    "    \n",
    "    ii2 = compute_ii2_TFIDF(ii2,n)\n",
    "    save_obj(ii2,'inverted_index_TFIDF')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242.7152338027954\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dict_with_TFIDF(texas1)\n",
    "print (time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna create a 'truth' matrix that has determined rows index as the terms of vocabulary (dicted by integers), and as columns index the documents ids.\n",
    "The matrix has stored 0 or tf-idf value in relation to the presence of i-th term in the i-th document.\n",
    "After the construction of this matrix, it will be easier to make the operations for Cosine Similarity for every query we could have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(cols,rows, inv_ind):\n",
    "    matrix = np.zeros(shape = (rows,cols), dtype=float)\n",
    "    for key in inv_ind.keys():\n",
    "        res_term_id = inv_ind[key]\n",
    "        for doc in res_term_id:\n",
    "            doc_tfidf = doc[1]\n",
    "            doc_id = int(doc[0][4:])\n",
    "            matrix[doc_id][key] = doc_tfidf\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_query_vector_and_take_docs(query, inv_ind_1):\n",
    "    query = remove_step(query)\n",
    "    query = query.split(' ')\n",
    "    query_vector = np.zeros(len(vocabulary))\n",
    "    iiL = len(inv_ind_1)\n",
    "    # query_vect = [  for i in range(len(vocabulary))]\n",
    "    # creating the vector of the query in [0, 1, 0, 2], the numbers depends on the occurrences of terms in the query, \n",
    "    #putted in the i-th position depending on the vocabulary\n",
    "    for el in query:\n",
    "        query_vector[vocabulary[el]] += 1        \n",
    "        compares = len(inv_ind_1[vocabulary[el]])\n",
    "        query_vector[vocabulary[el]] *= 1+log(iiL/compares) \n",
    "        \n",
    "    #we need to take the indices from the numpy array - tricky\n",
    "    non_zero = [el.tolist() for el in query_vector.nonzero()][0]\n",
    "    docs = set.intersection(*[set(inv_ind_1[i]) for i in non_zero])\n",
    "    docs = list(docs)\n",
    "    return query_vector, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the matrix, the vectorized query and docs. \n",
    "We will use the matrix to take the vectorized document with all the tfidf related to each term.\n",
    "Docs need to have the presence of all the words present in the query.\n",
    "This check is done using the row of the matrix (that is the vector of the i-th document taken in consideration). \n",
    "Thus, it will be possible to compute the Cosine Similarity and first ranking of documents related to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs(query_vector, matrix, docs, k):  \n",
    "    heap = []\n",
    "    #take the non zero values indexes into the query vector \n",
    "    non_zero = [el.tolist() for el in query_vector.nonzero()][0]\n",
    "     \n",
    "    for doc in docs:\n",
    "        # for each doc that contains one term of the query\n",
    "        doc_id = int(doc[4:])\n",
    "        # I take the row vector from the matrix \n",
    "        doc_vector = matrix[doc_id]\n",
    "        \n",
    "        # Taking the indexes of the ( document ) row vector related to the position of the query\n",
    "        query_words_doc = np.take(doc_vector, non_zero)\n",
    "        # take off the zero values from the row vector (I check where the document doesn't have a term of the query)\n",
    "        query_words_doc = query_words_doc.nonzero()\n",
    "        \n",
    "        query_words_doc = (query_words_doc)[0]\n",
    "        \n",
    "        if len(query_words_doc) == len(non_zero):\n",
    "            \n",
    "            #compute cosine similarity\n",
    "            cs = 1 - spatial.distance.cosine(query_words_doc,non_zero)\n",
    "            \n",
    "            heappush(heap, ('doc_'+str(doc_id),cs))\n",
    "    \n",
    "    first_k_docs_needed = [heapq.heappop(heap) for i in range(k)]\n",
    "    docs_len = len(first_k_docs_needed)\n",
    "    \n",
    "    list_for_df=[]\n",
    "    for i in range(docs_len):\n",
    "        with open (\"data/docs/\" + first_k_docs_needed[i][0] + '.tsv') as doc:\n",
    "            row = doc.read()\n",
    "            lst = row.split('\\t')\n",
    "            lst = [lst[7],lst[4],lst[2],lst[8], round(first_k_docs_needed[i][1], 2)]\n",
    "            list_for_df.append(lst)\n",
    "        \n",
    "    df=pd.DataFrame(list_for_df, columns=['Title', 'Description', 'City', 'Url', 'Similarity'])\n",
    "    \n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data we need\n",
    "vocabulary = load_obj('vocabulary')\n",
    "rows = len(vocabulary)\n",
    "cols = 18259#len(texas1)\n",
    "ii1 = load_obj('inverted_index_1')\n",
    "ii2 = load_obj('inverted_index_TFIDF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.443395614624023\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#functions\n",
    "matrix = build_matrix(rows, cols, ii2)\n",
    "query = \"room with private bathroom\"\n",
    "vec, lista = compute_query_vector_and_take_docs(query, ii1)\n",
    "\n",
    "cosines = cs(vec, matrix, lista, 5)\n",
    "cosines\n",
    "\n",
    "print (time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>City</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Private rooms/bathroom 10min from IAH airport</td>\n",
       "      <td>Welcome to stay in private room with queen bed...</td>\n",
       "      <td>Humble</td>\n",
       "      <td>https://www.airbnb.com/rooms/18520444?location...</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private Room near Fiesta Texas</td>\n",
       "      <td>Lovely quiet neighborhood just outside San Ant...</td>\n",
       "      <td>Helotes</td>\n",
       "      <td>https://www.airbnb.com/rooms/6360252?location=...</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Stay at Home - Private &amp; Safe near Airport</td>\n",
       "      <td>Well maintained room and bathroom. House is si...</td>\n",
       "      <td>Irving</td>\n",
       "      <td>https://www.airbnb.com/rooms/19000018?location...</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home Sweet Home in Burleson Texas</td>\n",
       "      <td>Beautiful House with 5 bedrooms, 3 bathrooms, ...</td>\n",
       "      <td>Burleson</td>\n",
       "      <td>https://www.airbnb.com/rooms/7605541?location=...</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In-Home Apt, Private Entry, Modern</td>\n",
       "      <td>Beautiful, clean, private, modern duplex-like ...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>https://www.airbnb.com/rooms/7747837?location=...</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    2 Private rooms/bathroom 10min from IAH airport   \n",
       "1                     Private Room near Fiesta Texas   \n",
       "2  Luxury Stay at Home - Private & Safe near Airport   \n",
       "3                  Home Sweet Home in Burleson Texas   \n",
       "4                 In-Home Apt, Private Entry, Modern   \n",
       "\n",
       "                                         Description      City  \\\n",
       "0  Welcome to stay in private room with queen bed...    Humble   \n",
       "1  Lovely quiet neighborhood just outside San Ant...   Helotes   \n",
       "2  Well maintained room and bathroom. House is si...    Irving   \n",
       "3  Beautiful House with 5 bedrooms, 3 bathrooms, ...  Burleson   \n",
       "4  Beautiful, clean, private, modern duplex-like ...    Austin   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.airbnb.com/rooms/18520444?location...        0.96  \n",
       "1  https://www.airbnb.com/rooms/6360252?location=...        0.96  \n",
       "2  https://www.airbnb.com/rooms/19000018?location...        0.96  \n",
       "3  https://www.airbnb.com/rooms/7605541?location=...        0.96  \n",
       "4  https://www.airbnb.com/rooms/7747837?location=...        0.96  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "del PorterStemmer, compute_query_vector_and_take_docs, cols, csv, defaultdict, heapify, heappop, heappush, ii1, ii2, load_obj, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "del texas1, path1, path2, stemmed_path, sp, vocabulary, string, non_zero, np, rows, save_obj, sc, remove_step,lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stopwords, create_vocabulary_and_ii1, build_matrix, log, word_tokenize, pickle, preprocessing,cs,heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pd, spatial, nltk, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable      Type        Data/Info\n",
      "-----------------------------------\n",
      "defaultdict   type        <class 'collections.defaultdict'>\n",
      "load_obj      function    <function load_obj at 0x00000276CA393950>\n",
      "nltk          module      <module 'nltk' from 'C:\\\\<...>ages\\\\nltk\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
